#!/usr/bin/env python3
"""
æ•°æ®é›†è·¯å¾„è¯Šæ–­è„šæœ¬
ç”¨äºåœ¨ Kaggle ä¸Šè°ƒè¯•æ•°æ®é›†åŠ è½½é—®é¢˜
"""

import os
import sys
from pathlib import Path


def debug_dataset_path():
    """è°ƒè¯•æ•°æ®é›†è·¯å¾„"""

    # æ£€æŸ¥è·¯å¾„
    dataset_path = "/kaggle/input/levir-cc-dateset/LEVIR-CC"

    print("=" * 60)
    print("æ•°æ®é›†è·¯å¾„è¯Šæ–­")
    print("=" * 60)

    print(f"\nğŸ“ æ£€æŸ¥è·¯å¾„: {dataset_path}")
    print(f"   è·¯å¾„å­˜åœ¨: {os.path.exists(dataset_path)}")

    if not os.path.exists(dataset_path):
        print("âŒ è·¯å¾„ä¸å­˜åœ¨ï¼")

        # æ£€æŸ¥ä¸Šçº§è·¯å¾„
        parent_path = "/kaggle/input/levir-cc-dateset"
        print(f"\nğŸ“ æ£€æŸ¥ä¸Šçº§è·¯å¾„: {parent_path}")
        print(f"   è·¯å¾„å­˜åœ¨: {os.path.exists(parent_path)}")

        if os.path.exists(parent_path):
            print(f"\n   å†…å®¹:")
            for item in os.listdir(parent_path):
                print(f"     - {item}")

        return 1

    # åˆ—å‡ºç›®å½•å†…å®¹
    print(f"\nğŸ“‚ ç›®å½•å†…å®¹:")
    path_obj = Path(dataset_path)

    for item in sorted(path_obj.iterdir()):
        if item.is_dir():
            # ç»Ÿè®¡å­é¡¹æ•°é‡
            try:
                count = len(list(item.iterdir()))
                print(f"   ğŸ“ {item.name}/ ({count} é¡¹)")
            except:
                print(f"   ğŸ“ {item.name}/")
        else:
            # æ˜¾ç¤ºæ–‡ä»¶å¤§å°
            size_mb = item.stat().st_size / (1024 * 1024)
            print(f"   ğŸ“„ {item.name} ({size_mb:.2f} MB)")

    # æ£€æŸ¥ Arrow æ–‡ä»¶
    print(f"\nğŸ” æŸ¥æ‰¾ Arrow æ–‡ä»¶:")
    arrow_files = list(path_obj.glob('*.arrow'))

    if arrow_files:
        print(f"   âœ… æ‰¾åˆ° {len(arrow_files)} ä¸ª Arrow æ–‡ä»¶:")
        for f in arrow_files:
            size_mb = f.stat().st_size / (1024 * 1024)
            print(f"      - {f.name} ({size_mb:.2f} MB)")
    else:
        print(f"   âŒ æœªæ‰¾åˆ° Arrow æ–‡ä»¶")

    # æ£€æŸ¥å›¾åƒç›®å½•
    print(f"\nğŸ” æŸ¥æ‰¾å›¾åƒç›®å½•:")
    image_dirs = [
        path_obj / 'images' / 'train' / 'A',
        path_obj / 'images' / 'train' / 'B',
        path_obj / 'A',
        path_obj / 'B',
        path_obj / 'train' / 'A',
        path_obj / 'train' / 'B',
    ]

    found_image_dirs = False
    for dir_path in image_dirs:
        if dir_path.exists():
            try:
                count = len(list(dir_path.glob('*.png')) + list(dir_path.glob('*.jpg')))
                print(f"   âœ… {dir_path.relative_to(path_obj)} ({count} å›¾åƒ)")
                found_image_dirs = True
            except:
                print(f"   âœ… {dir_path.relative_to(path_obj)}")

    if not found_image_dirs:
        print(f"   âŒ æœªæ‰¾åˆ°å›¾åƒç›®å½•")

    # æµ‹è¯•åŠ è½½
    print(f"\n" + "=" * 60)
    print("æµ‹è¯•æ•°æ®åŠ è½½")
    print("=" * 60)

    try:
        from src.dataset import load_raw_levir_cc_dataset

        print(f"\nè°ƒç”¨ load_raw_levir_cc_dataset('{dataset_path}')...")
        result = load_raw_levir_cc_dataset(dataset_path)

        print(f"\nâœ… åŠ è½½æˆåŠŸ!")
        print(f"   ç»“æœç±»å‹: {type(result).__name__}")

        if hasattr(result, '__len__'):
            print(f"   æ ·æœ¬æ•°é‡: {len(result)}")

        if hasattr(result, 'column_names'):
            print(f"   åˆ—å: {result.column_names}")

        return 0

    except Exception as e:
        print(f"\nâŒ åŠ è½½å¤±è´¥:")
        print(f"   é”™è¯¯: {e}")

        import traceback
        print(f"\nå®Œæ•´é”™è¯¯ä¿¡æ¯:")
        traceback.print_exc()

        return 1


if __name__ == "__main__":
    sys.exit(debug_dataset_path())

