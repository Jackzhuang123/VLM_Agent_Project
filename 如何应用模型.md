# è®­ç»ƒå®Œæˆåå¦‚ä½•åº”ç”¨æ¨¡å‹

## ğŸ“Œ æ¦‚è¿°

è®­ç»ƒå®Œæˆåï¼Œæ¨¡å‹æ£€æŸ¥ç‚¹ï¼ˆåŒ…å«è®­ç»ƒå¥½çš„æƒé‡ï¼‰ä¼šè‡ªåŠ¨ä¿å­˜åœ¨è¾“å‡ºç›®å½•ä¸­ã€‚æœ¬æ–‡è¯´æ˜å¦‚ä½•ä½¿ç”¨è¿™äº›æ£€æŸ¥ç‚¹è¿›è¡Œæ¨ç†é¢„æµ‹ã€‚

---

## ğŸš€ å¿«é€Ÿå¼€å§‹ï¼ˆæ¨èï¼‰

### æ–¹æ³• 1ï¼šä½¿ç”¨å¿«é€Ÿæ¨ç†è„šæœ¬ï¼ˆæœ€ç®€å•ï¼‰

```bash
# åŸºç¡€æ¨ç†
python quick_inference.py \
    --use-best \
    --image1 before.jpg \
    --image2 after.jpg \
    --caption "building construction area"

# å¯è§†åŒ–ç»“æœ
python quick_inference.py \
    --use-best \
    --visualize \
    --image1 before.jpg \
    --image2 after.jpg \
    --caption "building construction area" \
    --output result.jpg
```

**è¾“å‡ºç¤ºä¾‹ï¼š**
```
============================================================
VLM-VLA Agent æ¨ç†
============================================================
æ£€æŸ¥ç‚¹: /path/to/checkpoint_best.pt
å›¾åƒ 1: before.jpg
å›¾åƒ 2: after.jpg
æ–‡æœ¬: building construction area
è®¾å¤‡: cuda
============================================================

æ­£åœ¨æ¨ç†...

============================================================
æ¨ç†ç»“æœ
============================================================
åŠ¨ä½œå‘é‡: [0.456789 0.234567 0.789012]
  ä¸­å¿ƒ X åæ ‡: 0.456789
  ä¸­å¿ƒ Y åæ ‡: 0.234567
  å°ºåº¦å› å­: 0.789012
============================================================

âœ… æ¨ç†å®Œæˆï¼
```

---

## ğŸ“š è¯¦ç»†ä½¿ç”¨æ–¹æ³•

### æ–¹æ³• 2ï¼šåœ¨ Python ä»£ç ä¸­ä½¿ç”¨

#### åŸºç¡€æ¨ç†

```python
from src.inference import VLMInference

# åˆå§‹åŒ–æ¨ç†å™¨
inference = VLMInference(
    checkpoint_path="output/checkpoint_20260116_075102/checkpoint_best.pt"
)

# æ‰§è¡Œæ¨ç†
result = inference.predict(
    image_t1_path="before.jpg",
    image_t2_path="after.jpg",
    caption="Building construction started"
)

# è·å–ç»“æœ
print(f"ä¸­å¿ƒ x: {result['cx']:.4f}")
print(f"ä¸­å¿ƒ y: {result['cy']:.4f}")
print(f"ç¼©æ”¾: {result['scale']:.4f}")
```

#### æ‰¹å¤„ç†æ¨ç†

```python
from src.inference import VLMInference

inference = VLMInference(checkpoint_path="checkpoint_best.pt")

# å‡†å¤‡å¤šä¸ªæ ·æœ¬
image_pairs = [
    ("img1_before.jpg", "img1_after.jpg"),
    ("img2_before.jpg", "img2_after.jpg"),
    ("img3_before.jpg", "img3_after.jpg"),
]

captions = [
    "Building area changes",
    "Road expansion detected",
    "New construction site",
]

# æ‰¹å¤„ç†æ¨ç†
results = inference.batch_predict(image_pairs, captions)

# å¤„ç†ç»“æœ
for i, result in enumerate(results):
    print(f"æ ·æœ¬ {i+1}:")
    print(f"  cx={result['cx']:.4f}, cy={result['cy']:.4f}, scale={result['scale']:.4f}")
```

#### å¯è§†åŒ–ç»“æœ

```python
from src.inference import VLMInference

inference = VLMInference(checkpoint_path="checkpoint_best.pt")

# æ¨ç†
result = inference.predict("before.jpg", "after.jpg", "Changes detected")

# å¯è§†åŒ–
vis_img = inference.visualize_result(
    "before.jpg",
    "after.jpg",
    result,
    output_path="visualization.jpg"
)
```

---

## ğŸ“ æ£€æŸ¥ç‚¹æ–‡ä»¶è¯´æ˜

### æ£€æŸ¥ç‚¹ç›®å½•ç»“æ„

```
output/
â””â”€â”€ checkpoint_20260116_075102/          # æ—¶é—´æˆ³æ£€æŸ¥ç‚¹ç›®å½•
    â”œâ”€â”€ checkpoint_best.pt               # â­ éªŒè¯é›†ä¸Šæœ€ä¼˜æ¨¡å‹ï¼ˆæ¨èç”¨äºæ¨ç†ï¼‰
    â”œâ”€â”€ checkpoint_latest.pt             # æœ€åä¸€ä¸ªä¿å­˜çš„æ£€æŸ¥ç‚¹
    â”œâ”€â”€ checkpoint_step_X.pt             # ç¬¬ X æ­¥çš„ä¸­é—´æ£€æŸ¥ç‚¹
    â””â”€â”€ metrics.json                     # è®­ç»ƒæŒ‡æ ‡æ‘˜è¦
```

### æ–‡ä»¶è¯´æ˜

| æ–‡ä»¶ | ç”¨é€” | æ¨è |
|------|------|------|
| `checkpoint_best.pt` | éªŒè¯é›†ä¸Šè¡¨ç°æœ€å¥½çš„æ¨¡å‹ | âœ… æ¨ç† |
| `checkpoint_latest.pt` | æœ€åä¿å­˜çš„æ£€æŸ¥ç‚¹ | æ¢å¤è®­ç»ƒ |
| `checkpoint_step_X.pt` | ä¸­é—´æ£€æŸ¥ç‚¹ | æ¢å¤è®­ç»ƒ |

**å»ºè®®ï¼šå§‹ç»ˆä½¿ç”¨ `checkpoint_best.pt` è¿›è¡Œæ¨ç†ï¼Œå› ä¸ºè¿™æ˜¯éªŒè¯é›†ä¸Šè¡¨ç°æœ€å¥½çš„æ¨¡å‹ã€‚**

---

## ğŸ” æ¨ç†è¾“å‡ºè¯´æ˜

### åŠ¨ä½œå‘é‡å«ä¹‰

æ¨¡å‹è¾“å‡º 3 ä¸ªæ•°å€¼çš„åŠ¨ä½œå‘é‡ `[cx, cy, scale]`ï¼Œå‡å½’ä¸€åŒ–åˆ° [0, 1]ï¼š

```
[cx, cy, scale]
 â†“   â†“    â†“
 |   |    â””â”€ å˜åŒ–å°ºåº¦ï¼ˆ0=å¾®å°ï¼Œ1=å¤§è§„æ¨¡ï¼‰
 |   â””â”€â”€â”€â”€â”€â”€ Y åæ ‡ï¼ˆ0=ä¸Šï¼Œ1=ä¸‹ï¼‰
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ X åæ ‡ï¼ˆ0=å·¦ï¼Œ1=å³ï¼‰
```

### è½¬æ¢ä¸ºåƒç´ åæ ‡

```python
# å¦‚æœå›¾åƒåˆ†è¾¨ç‡ä¸º H Ã— W
cx, cy, scale = result['cx'], result['cy'], result['scale']

# è½¬æ¢ä¸ºåƒç´ åæ ‡
center_x_pixel = int(cx * W)
center_y_pixel = int(cy * H)
region_radius = int(scale * max(H, W) / 2)

# ç»˜åˆ¶æ£€æµ‹åŒºåŸŸ
import cv2
image = cv2.imread("image.jpg")
cv2.circle(image, (center_x_pixel, center_y_pixel), region_radius, (0, 255, 0), 2)
cv2.imwrite("result.jpg", image)
```

---

## ğŸ¯ å¸¸ç”¨åœºæ™¯

### åœºæ™¯ 1ï¼šå•å¼ å›¾åƒå¯¹æ¨ç†

```python
from src.inference import VLMInference

inference = VLMInference("checkpoint_best.pt")
result = inference.predict("img1.jpg", "img2.jpg", "city changes")

print(f"å˜åŒ–ä¸­å¿ƒ: ({result['cx']:.3f}, {result['cy']:.3f})")
print(f"å˜åŒ–è§„æ¨¡: {result['scale']:.3f}")
```

### åœºæ™¯ 2ï¼šå¤„ç†æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰å›¾åƒ

```python
from pathlib import Path
from src.inference import VLMInference

inference = VLMInference("checkpoint_best.pt")

# è·å–æ‰€æœ‰å›¾åƒå¯¹
image_dir = Path("images")
pairs = sorted(image_dir.glob("*_before.jpg"))

results = []
for before_img in pairs:
    after_img = before_img.parent / before_img.name.replace("_before", "_after")

    if after_img.exists():
        result = inference.predict(str(before_img), str(after_img), "image comparison")
        results.append({
            'image': before_img.name,
            'cx': result['cx'],
            'cy': result['cy'],
            'scale': result['scale'],
        })

# ä¿å­˜ç»“æœ
import json
with open("results.json", "w") as f:
    json.dump(results, f, indent=2)
```

### åœºæ™¯ 3ï¼šKaggle Notebook ä¸­ä½¿ç”¨

```python
from src.inference import VLMInference

# ä½¿ç”¨ Kaggle è·¯å¾„
checkpoint = "/kaggle/working/output/checkpoint_XXX/checkpoint_best.pt"
inference = VLMInference(checkpoint_path=checkpoint)

# ä»è¾“å…¥æ•°æ®é›†è¯»å–å›¾åƒ
result = inference.predict(
    "/kaggle/input/dataset/image1.jpg",
    "/kaggle/input/dataset/image2.jpg",
    "building changes"
)

# è¾“å‡ºç»“æœåˆ° working ç›®å½•
output = {
    'predictions': {
        'cx': result['cx'],
        'cy': result['cy'],
        'scale': result['scale'],
    }
}

import json
with open("/kaggle/working/predictions.json", "w") as f:
    json.dump(output, f, indent=2)
```

---

## âš™ï¸ é«˜çº§é€‰é¡¹

### è‡ªå®šä¹‰æ¨¡å‹è·¯å¾„

```python
from src.inference import VLMInference

inference = VLMInference(
    checkpoint_path="checkpoint_best.pt",
    clip_path="/path/to/custom/clip",
    llm_path="/path/to/custom/llm",
    device="cuda"
)
```

### ä½¿ç”¨ CPU æ¨ç†

```python
from src.inference import VLMInference

inference = VLMInference(
    checkpoint_path="checkpoint_best.pt",
    device="cpu"  # é€Ÿåº¦è¾ƒæ…¢ï¼Œä½†æ— éœ€ GPU
)
```

### æ‰¹å¤„ç†ä¼˜åŒ–

```python
# ä½¿ç”¨è¾ƒå¤§çš„æ‰¹å¤§å°åŠ å¿«æ¨ç†
pairs = [(f"img{i}_before.jpg", f"img{i}_after.jpg") for i in range(100)]
captions = ["change"] * 100

results = inference.batch_predict(pairs, captions)
# æ¯”å•ä¸ªæ¨ç†å¿« 2-3 å€
```

---

## ğŸ”§ æ•…éšœæ’æŸ¥

### é—®é¢˜ 1ï¼šæ‰¾ä¸åˆ°æ£€æŸ¥ç‚¹

```python
# è‡ªåŠ¨æŸ¥æ‰¾æœ€ä¼˜æ£€æŸ¥ç‚¹
from pathlib import Path
from src.config import Config

output_dir = Path(Config.OUTPUT_DIR)
checkpoints = list(output_dir.glob("checkpoint_*/checkpoint_best.pt"))

if checkpoints:
    latest_ckpt = sorted(checkpoints, key=lambda x: x.stat().st_mtime)[-1]
    print(f"ä½¿ç”¨æ£€æŸ¥ç‚¹: {latest_ckpt}")
```

### é—®é¢˜ 2ï¼šæ¨ç†ç»“æœä¸åˆç†

- ç¡®ä¿å›¾åƒè´¨é‡è‰¯å¥½ï¼ˆä¸æ¨¡ç³Šã€ä¸å¤ªæš—ï¼‰
- ç¡®ä¿æ–‡æœ¬æè¿°å‡†ç¡®ã€å…·ä½“
- æ£€æŸ¥æ¨¡å‹æ˜¯å¦åœ¨ç›¸ä¼¼æ•°æ®é›†ä¸Šè®­ç»ƒè¿‡

### é—®é¢˜ 3ï¼šå†…å­˜ä¸è¶³

```python
# ä½¿ç”¨ CPU æ¨ç†ï¼ˆé€Ÿåº¦è¾ƒæ…¢ï¼‰
inference = VLMInference(checkpoint_path, device="cpu")

# æˆ–å‡å°æ‰¹å¤§å°
results = inference.batch_predict(pairs[:10], captions[:10])  # 10 ä¸ªæ ·æœ¬
```

### é—®é¢˜ 4ï¼šæ¨ç†é€Ÿåº¦æ…¢

- ä½¿ç”¨ GPU æ¨ç†ï¼š`device="cuda"`
- ä½¿ç”¨æ‰¹å¤„ç†è€Œä¸æ˜¯å•ä¸ªæ¨ç†
- å‡å°è¾“å…¥å›¾åƒåˆ†è¾¨ç‡ï¼ˆæ¨¡å‹ä¼šè‡ªåŠ¨è°ƒæ•´åˆ° 224Ã—224ï¼‰

---

## ğŸ“Š æ€§èƒ½å‚è€ƒ

### æ¨ç†é€Ÿåº¦ï¼ˆå‚è€ƒå€¼ï¼‰

| é…ç½® | å•æ ·æœ¬ | æ‰¹å¤§å° 4 | æ‰¹å¤§å° 16 |
|------|--------|---------|----------|
| GPU (NVIDIA T4) | 100-200ms | 30-50ms/æ ·æœ¬ | 20-30ms/æ ·æœ¬ |
| CPU | 1-2s | 300-500ms/æ ·æœ¬ | 200-300ms/æ ·æœ¬ |

### å†…å­˜å ç”¨

| ç»„ä»¶ | GPU æ˜¾å­˜ | CPU å†…å­˜ |
|------|---------|----------|
| æ¨¡å‹ | ~2.5GB | ~1.5GB |
| å›¾åƒç¼“å­˜ | ~0.5GB | ~0.3GB |
| **æ€»è®¡** | **~3GB** | **~2GB** |

---

## ğŸ“– æ›´å¤šä¿¡æ¯

è¯¦ç»†çš„æ¨ç†æŒ‡å—è¯·å‚è€ƒ `INFERENCE_GUIDE.md`

å¿«é€Ÿæ¨ç†è„šæœ¬å¸®åŠ©ï¼š
```bash
python quick_inference.py --help
```

---

## ğŸ“ æ€»ç»“

**æ¨ç†çš„ 3 ä¸ªæ­¥éª¤ï¼š**

1. **é€‰æ‹©æ£€æŸ¥ç‚¹**ï¼šä½¿ç”¨ `checkpoint_best.pt`
2. **åˆå§‹åŒ–æ¨ç†å™¨**ï¼š`VLMInference(checkpoint_path)`
3. **æ‰§è¡Œæ¨ç†**ï¼š`inference.predict(img1, img2, caption)`

**æ¨èçš„ä½¿ç”¨æ–¹å¼ï¼š**

- ğŸƒ **å¿«é€Ÿä½¿ç”¨**ï¼š`python quick_inference.py --use-best --image1 ... --image2 ... --caption ...`
- ğŸ“Š **æ‰¹å¤„ç†**ï¼šä½¿ç”¨ `batch_predict()` å¤„ç†å¤šä¸ªæ ·æœ¬
- ğŸ“ **é›†æˆä»£ç **ï¼šå¯¼å…¥ `VLMInference` åˆ°ä½ çš„é¡¹ç›®ä¸­

ç¥ä½ ä½¿ç”¨æ„‰å¿«ï¼ğŸ‰

