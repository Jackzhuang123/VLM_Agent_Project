# ğŸš€ å¿«é€Ÿå¼€å§‹æŒ‡å—

> VLM-VLA Agent å®Œæ•´éƒ¨ç½²æ•™ç¨‹ - æ”¯æŒæœ¬åœ°å’Œ Kaggle ç¯å¢ƒ

---

## ğŸ“‹ ç›®å½•

1. [ç¯å¢ƒå‡†å¤‡](#ç¯å¢ƒå‡†å¤‡)
2. [æœ¬åœ°éƒ¨ç½²](#æœ¬åœ°éƒ¨ç½²)
3. [Kaggle éƒ¨ç½²](#kaggle-éƒ¨ç½²)
4. [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)
5. [è®­ç»ƒç›‘æ§](#è®­ç»ƒç›‘æ§)

---

## ç¯å¢ƒå‡†å¤‡

### ç³»ç»Ÿè¦æ±‚

**æœ¬åœ°å¼€å‘**
```
Python: 3.8+
CUDA: 11.8+ (å¯é€‰ï¼Œç”¨äº GPU)
RAM: 16+ GB
ç£ç›˜: 20+ GB
```

**Kaggle ç¯å¢ƒ**
```
GPU: T4 x2 (æ¨è)
Python: 3.10
RAM: 13 GB (è‡ªåŠ¨æä¾›)
ç£ç›˜: 100+ GB (è‡ªåŠ¨æä¾›)
```

### éªŒè¯é¡¹ç›®ç»“æ„

```bash
cd VLM_Agent_Project
python check_setup.py
```

é¢„æœŸè¾“å‡ºï¼š
```
âœ… é¡¹ç›®ç»“æ„
âœ… ä¾èµ–é¡¹
âœ… é…ç½®
âœ… PyTorch/GPU
```

---

## æœ¬åœ°éƒ¨ç½²

### Step 1: å®‰è£…ä¾èµ–

```bash
# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python -m venv venv

# æ¿€æ´»ç¯å¢ƒ
# macOS/Linux:
source venv/bin/activate

# Windows:
venv\Scripts\activate

# å®‰è£…ä¾èµ–
pip install -r requirements.txt
```

### Step 2: å‡†å¤‡æ•°æ®ï¼ˆå¯é€‰ï¼‰

```bash
# åˆ›å»ºæ•°æ®ç›®å½•
mkdir -p data models

# æ•°æ®é›†æ”¯æŒå¤šç§æ ¼å¼ï¼š
# 1. Arrow æ ¼å¼ï¼ˆHuggingFaceï¼‰
#    - data/Levir-CC-dataset/levir-cc-train.arrow
#
# 2. åŸå§‹å›¾åƒ + JSON æ ‡æ³¨ï¼ˆæ¨èç”¨äº Kaggleï¼‰
#    - data/Levir-CC-dataset/images/train/A/  ï¼ˆè®­ç»ƒé›†å›¾åƒAï¼‰
#    - data/Levir-CC-dataset/images/train/B/  ï¼ˆè®­ç»ƒé›†å›¾åƒBï¼‰
#    - data/Levir-CC-dataset/images/val/A/    ï¼ˆéªŒè¯é›†å›¾åƒAï¼‰
#    - data/Levir-CC-dataset/images/val/B/    ï¼ˆéªŒè¯é›†å›¾åƒBï¼‰
#    - data/Levir-CC-dataset/LevirCCcaptions.json  ï¼ˆæ ‡æ³¨æ–‡ä»¶ï¼‰
#
# 3. ç®€åŒ–ç»“æ„
#    - data/Levir-CC-dataset/train/A/
#    - data/Levir-CC-dataset/train/B/
#    - data/Levir-CC-dataset/val/A/
#    - data/Levir-CC-dataset/val/B/

# ä¸‹è½½æˆ–å¤åˆ¶æ¨¡å‹åˆ°ï¼š
# - models/clip-vit-b32/    ï¼ˆCLIP æ¨¡å‹ï¼‰
# - models/qwen2.5-0.5b/    ï¼ˆQwen æ¨¡å‹ï¼‰
```

**æ³¨æ„**ï¼šå¦‚æœä½¿ç”¨ Kaggle æ•°æ®é›†ï¼Œæ•°æ®ç»“æ„åº”ä¸æœ¬åœ°ä¿æŒä¸€è‡´

### Step 3: éªŒè¯é…ç½®

```bash
# æ‰“å°é…ç½®ä¿¡æ¯
python -m src.config

# æµ‹è¯•æ•°æ®åŠ è½½ï¼ˆéœ€è¦æ•°æ®ï¼‰
python -m src.dataset

# æµ‹è¯•æ¨¡å‹åˆ›å»º
python -m src.model
```

### Step 4: å¼€å§‹è®­ç»ƒ

```bash
# å¯åŠ¨è®­ç»ƒ
python -m src.train

# è®­ç»ƒå°†è‡ªåŠ¨ï¼š
# - åŠ è½½æ•°æ®
# - åˆå§‹åŒ–æ¨¡å‹
# - å¼€å§‹è®­ç»ƒå¾ªç¯
# - å®šæœŸä¿å­˜æ£€æŸ¥ç‚¹
```

è¾“å‡ºç¤ºä¾‹ï¼š
```
============================================================
åˆå§‹åŒ–è®­ç»ƒå™¨
============================================================
è®¾å¤‡: cuda
CUDA å¯ç”¨: True
CUDA è®¾å¤‡: Tesla T4
CUDA å†…å­˜: 12.00 GB

============================================================
åŠ è½½æ•°æ®é›†
============================================================
âœ… æ•°æ®é›†å·²åˆå§‹åŒ–ï¼Œå…± 10000 ä¸ªæ ·æœ¬
è®­ç»ƒæ‰¹æ¬¡: 2250
éªŒè¯æ‰¹æ¬¡: 250

Epoch 1/10 - è®­ç»ƒæŸå¤±: 0.8432, åŠ¨ä½œæŸå¤±: 0.5621
Epoch 1/10 - éªŒè¯æŸå¤±: 0.7854, åŠ¨ä½œæŸå¤±: 0.5123
âœ… æ£€æŸ¥ç‚¹å·²ä¿å­˜: checkpoint_step_500.pt
```

---

## Kaggle éƒ¨ç½²

### å‡†å¤‡å·¥ä½œ

#### 1. åˆ›å»º Kaggle Notebook

- è®¿é—® [https://www.kaggle.com](https://www.kaggle.com)
- ç‚¹å‡» "New â†’ Notebook"

#### 2. é…ç½® Notebook è®¾ç½®

**å³ä¾§é¢æ¿ - Settings:**
- Accelerator: **GPU T4 x2** âœ…
- Language: Python 3.10 âœ…
- Internet: On (ä»…ç”¨äºå…‹éš†ä»£ç )

**å³ä¾§é¢æ¿ - Input:**
ç‚¹å‡» "Add Data" æ·»åŠ ä»¥ä¸‹æ•°æ®é›†ï¼š
- âœ… `levir-cc-dateset`
- âœ… `clip-vit-b32`
- âœ… `qwen2.5-0.5b`

---

### Kaggle Notebook Cells

#### Cell 1ï¸âƒ£: éªŒè¯è·¯å¾„

```python
import os

print("ğŸ” æ£€æŸ¥è¾“å…¥ç›®å½•ç»“æ„:")
print("="*60)

# åˆ—å‡ºæ‰€æœ‰æ•°æ®é›†
datasets = os.listdir("/kaggle/input")
for ds in datasets:
    print(f"  ğŸ“ {ds}/")

print("="*60)

# éªŒè¯å…³é”®æ–‡ä»¶
checks = [
    ("/kaggle/input/levir-cc-dateset/LEVIR-CC", "âœ… æ•°æ®é›†"),
    ("/kaggle/input/clip-vit-b32/config.json", "âœ… CLIP æ¨¡å‹"),
    ("/kaggle/input/qwen2.5-0.5b/config.json", "âœ… Qwen æ¨¡å‹"),
]

print("\néªŒè¯å…³é”®è·¯å¾„:")
print("="*60)
for path, label in checks:
    status = "âœ…" if os.path.exists(path) else "âŒ"
    print(f"{status} {label}: {path}")
print("="*60)
```

**é¢„æœŸè¾“å‡º**: æ‰€æœ‰æ£€æŸ¥éƒ½æ˜¯ âœ…

---

#### Cell 2ï¸âƒ£: å…‹éš†ä»“åº“å’Œå®‰è£…ä¾èµ–

```python
# å…‹éš†ä»“åº“ï¼ˆæ›¿æ¢ä¸ºä½ çš„ GitHub URLï¼‰
!git clone https://github.com/YOUR_USERNAME/VLM_Agent_Project.git
%cd VLM_Agent_Project

# å®‰è£…ç¼ºå¤±çš„åŒ…ï¼ˆKaggle å·²é¢„è£… torchã€transformers ç­‰ï¼‰
!pip install -q datasets bitsandbytes peft accelerate

# éªŒè¯å®‰è£…
!python -m src.config
```

**é¢„æœŸè¾“å‡º**: é…ç½®æˆåŠŸæ‰“å°

---

#### Cell 3ï¸âƒ£: å¯åŠ¨è®­ç»ƒ

```python
# è¿è¡Œè®­ç»ƒ
!python -m src.train
```

è¿™å°†å¯åŠ¨å®Œæ•´çš„è®­ç»ƒæµç¨‹ï¼š
- âœ… åŠ è½½æ•°æ®ï¼ˆArrow æ ¼å¼ï¼‰
- âœ… åˆå§‹åŒ–æ¨¡å‹ï¼ˆCLIP + Qwen + LoRAï¼‰
- âœ… è®­ç»ƒå¾ªç¯ï¼ˆ10 è½®ï¼‰
- âœ… å®šæœŸä¿å­˜æ£€æŸ¥ç‚¹ï¼ˆæ¯ 500 æ­¥ï¼‰

**é¢„è®¡æ—¶é—´**: 30-40 åˆ†é’Ÿï¼ˆT4 GPUï¼Œ10 è½®ï¼‰

---

#### Cell 4ï¸âƒ£: ç›‘æ§è¿›åº¦ï¼ˆå¯é€‰ï¼‰

```python
import os
import json
from pathlib import Path

# æ£€æŸ¥è¾“å‡ºç›®å½•
output_dir = Path("/kaggle/working/output")
if output_dir.exists():
    print("ğŸ“Š è®­ç»ƒç»“æœ:")
    print("="*60)

    for checkpoint_dir in output_dir.iterdir():
        if checkpoint_dir.is_dir():
            print(f"\nğŸ“ {checkpoint_dir.name}/")

            # åˆ—å‡ºæ£€æŸ¥ç‚¹
            for file in checkpoint_dir.glob("*.pt"):
                size_mb = file.stat().st_size / 1e6
                print(f"  ğŸ’¾ {file.name} ({size_mb:.1f} MB)")

            # æ˜¾ç¤ºæŒ‡æ ‡
            metrics_file = checkpoint_dir / "metrics.json"
            if metrics_file.exists():
                with open(metrics_file) as f:
                    metrics = json.load(f)
                print(f"  ğŸ“ˆ æœ€ç»ˆè®­ç»ƒæŸå¤±: {metrics['train']['final_loss']:.4f}")
                print(f"  ğŸ“Š æœ€ç»ˆéªŒè¯æŸå¤±: {metrics['val']['final_loss']:.4f}")
else:
    print("â³ è®­ç»ƒä»åœ¨è¿›è¡Œä¸­æˆ–å°šæœªå¼€å§‹...")
```

---

#### Cell 5ï¸âƒ£: ä¸‹è½½ç»“æœï¼ˆå¯é€‰ï¼‰

```python
# åˆ›å»ºç»“æœçš„å‹ç¼©åŒ…
import shutil
import os

output_dir = "/kaggle/working/output"
if os.path.exists(output_dir):
    # æ‰¾åˆ°æœ€æ–°çš„æ£€æŸ¥ç‚¹ç›®å½•
    checkpoint_dirs = sorted(
        [d for d in os.listdir(output_dir) if os.path.isdir(os.path.join(output_dir, d))],
        reverse=True
    )

    if checkpoint_dirs:
        latest_checkpoint = checkpoint_dirs[0]
        checkpoint_path = os.path.join(output_dir, latest_checkpoint)

        # åˆ›å»º zip
        print(f"ğŸ“¦ æ­£åœ¨ä¸º {latest_checkpoint} åˆ›å»º zip æ–‡ä»¶...")
        shutil.make_archive(
            f"/kaggle/working/{latest_checkpoint}",
            'zip',
            output_dir,
            latest_checkpoint
        )

        print("âœ… å‡†å¤‡ä¸‹è½½!")
        print(f"   æ–‡ä»¶: /kaggle/working/{latest_checkpoint}.zip")
        print(f"\nğŸ’¡ ä¸‹è½½æ–¹å¼: ç‚¹å‡»å³ä¾§ Output æ ‡ç­¾ â†’ æ‰¾åˆ° zip æ–‡ä»¶ â†’ ä¸‹è½½")
```

---

## å¸¸è§é—®é¢˜

### â“ é”™è¯¯ï¼š"Dataset not found"

**åŸå› **: æ•°æ®é›†è·¯å¾„ä¸æ­£ç¡®æˆ–æ•°æ®æ ¼å¼ä¸æ”¯æŒ

**æ”¯æŒçš„æ•°æ®æ ¼å¼**:
1. **Arrow æ ¼å¼**ï¼ˆHuggingFaceï¼‰
   ```
   data/Levir-CC-dataset/levir-cc-train.arrow
   ```

2. **åŸå§‹å›¾åƒç›®å½• + JSON æ ‡æ³¨**ï¼ˆæ¨èï¼‰
   ```
   data/Levir-CC-dataset/
   â”œâ”€â”€ images/
   â”‚   â”œâ”€â”€ train/A/, train/B/
   â”‚   â”œâ”€â”€ val/A/, val/B/
   â”‚   â””â”€â”€ test/A/, test/B/
   â””â”€â”€ LevirCCcaptions.json
   ```

3. **ç®€åŒ–ç›®å½•ç»“æ„**
   ```
   data/Levir-CC-dataset/
   â”œâ”€â”€ train/A/, train/B/
   â”œâ”€â”€ val/A/, val/B/
   â””â”€â”€ test/A/, test/B/
   ```

**è§£å†³æ–¹æ¡ˆ**:
```python
# åœ¨ Cell 1 ä¸­æ£€æŸ¥ç²¾ç¡®è·¯å¾„
import os
for root, dirs, files in os.walk("/kaggle/input"):
    level = root.replace("/kaggle/input", "").count(os.sep)
    indent = " " * 2 * level
    print(f"{indent}{os.path.basename(root)}/")
```

**ç³»ç»Ÿä¼šè‡ªåŠ¨å°è¯•æ£€æµ‹å’Œæ”¯æŒä¸Šè¿°æ‰€æœ‰æ ¼å¼ã€‚å¦‚æœä»ç„¶å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ•°æ®æ˜¯å¦å®Œæ•´ã€‚**

---

### â“ é”™è¯¯:"CUDA out of memory"

**åŸå› **: æ‰¹æ¬¡å¤§å°å¤ªå¤§æˆ–æ¨¡å‹å¤ªå¤§

**è§£å†³æ–¹æ¡ˆ**: ç¼–è¾‘ `src/config.py`
```python
# å‡å°æ‰¹æ¬¡å¤§å°
BATCH_SIZE = 2  # ä» 4 æ”¹ä¸º 2

# æˆ–å¢åŠ æ¢¯åº¦ç´¯ç§¯
GRADIENT_ACCUMULATION_STEPS = 2

# æˆ–ç¦ç”¨æ··åˆç²¾åº¦
USE_MIXED_PRECISION = False
```

---

### â“ é”™è¯¯ï¼š"local_files_only=True" é”™è¯¯

**åŸå› **: æ¨¡å‹æ–‡ä»¶ä¸å®Œæ•´

**è§£å†³æ–¹æ¡ˆ**: åœ¨ Cell 1 ä¸­éªŒè¯æ–‡ä»¶
```python
import os

model_paths = {
    "CLIP": "/kaggle/input/clip-vit-b32",
    "Qwen": "/kaggle/input/qwen2.5-0.5b",
}

for name, path in model_paths.items():
    print(f"\n{name} æ¨¡å‹æ–‡ä»¶:")
    if os.path.exists(path):
        for file in os.listdir(path):
            if not file.startswith('.'):
                print(f"  - {file}")
```

ç¡®ä¿åŒ…å«ï¼š
- âœ… `config.json`
- âœ… `model.safetensors` æˆ– `pytorch_model.bin`
- âœ… `tokenizer.json`
- âœ… `preprocessor_config.json` (CLIP)

---

### â“ è®­ç»ƒå¾ˆæ…¢

**åŸå› **: å¯èƒ½æ˜¯ I/O é™åˆ¶æˆ– CPU ç“¶é¢ˆ

**è§£å†³æ–¹æ¡ˆ**: åœ¨ `config.py` ä¸­å¢åŠ å·¥ä½œè¿›ç¨‹æ•°
```python
NUM_WORKERS = 8  # æ ¹æ® CPU æ ¸å¿ƒæ•°è°ƒæ•´
```

---

### â“ æ¨¡å‹æ²¡æœ‰ä¿å­˜

**åŸå› **: è¾“å‡ºç›®å½•å¯èƒ½ä¸å¯å†™

**è§£å†³æ–¹æ¡ˆ**:
```python
import os
from src.config import Config

# æ£€æŸ¥è¾“å‡ºç›®å½•
print(f"è¾“å‡ºç›®å½•: {Config.OUTPUT_DIR}")
print(f"å­˜åœ¨: {os.path.exists(Config.OUTPUT_DIR)}")
print(f"å¯å†™: {os.access(Config.OUTPUT_DIR, os.W_OK)}")

# åˆ›å»ºç›®å½•ï¼ˆå¦‚æœéœ€è¦ï¼‰
os.makedirs(Config.OUTPUT_DIR, exist_ok=True)
```

---

## è®­ç»ƒç›‘æ§

### æ—¥å¿—è¾“å‡ºè§£è¯»

```
Epoch 1/10 - è®­ç»ƒæŸå¤±: 0.8432, åŠ¨ä½œæŸå¤±: 0.5621
Epoch 1/10 - éªŒè¯æŸå¤±: 0.7854, åŠ¨ä½œæŸå¤±: 0.5123
âœ… æ£€æŸ¥ç‚¹å·²ä¿å­˜: checkpoint_step_500.pt
```

**å«ä¹‰**:
- **è®­ç»ƒæŸå¤±**: è®­ç»ƒé›†å¹³å‡æŸå¤±
- **åŠ¨ä½œæŸå¤±**: åŠ¨ä½œé¢„æµ‹æŸå¤±
- **éªŒè¯æŸå¤±**: éªŒè¯é›†å¹³å‡æŸå¤±
- å¦‚æœéªŒè¯æŸå¤±ä¸‹é™ï¼Œè¯´æ˜æ¨¡å‹åœ¨æ”¹è¿› âœ…

### æ€§èƒ½æŒ‡æ ‡

**ç†æƒ³æƒ…å†µï¼ˆT4 GPUï¼‰ï¼š**
- æ¯è½®æ¬¡ï¼š~2-3 åˆ†é’Ÿ
- 10 è½®æ€»æ—¶é—´ï¼š~25-30 åˆ†é’Ÿ
- å†…å­˜ä½¿ç”¨ï¼š8-10 GBï¼ˆT4 12GB æ˜¾å­˜ï¼‰

### æ£€æŸ¥ç‚¹ç»“æ„

è®­ç»ƒä¼šåˆ›å»ºä»¥ä¸‹æ–‡ä»¶ï¼š
```
/kaggle/working/output/checkpoint_YYYYMMDD_HHMMSS/
â”œâ”€â”€ checkpoint_step_500.pt      # ç¬¬ 500 æ­¥
â”œâ”€â”€ checkpoint_step_1000.pt     # ç¬¬ 1000 æ­¥
â”œâ”€â”€ checkpoint_best.pt          # æœ€ä½³æ¨¡å‹
â”œâ”€â”€ checkpoint_latest.pt        # æœ€æ–°æ£€æŸ¥ç‚¹
â””â”€â”€ metrics.json                # è®­ç»ƒæŒ‡æ ‡
```

---

## ğŸ¯ ä¸‹ä¸€æ­¥

è®­ç»ƒå®Œæˆåï¼š

### 1. ä¸‹è½½æ¨¡å‹
ä» Cell 5 çš„ zip æ–‡ä»¶ä¸‹è½½

### 2. åŠ è½½æ£€æŸ¥ç‚¹è¿›è¡Œæ¨ç†
```python
import torch
from src.model import create_model

# åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
checkpoint = torch.load("checkpoint_best.pt", map_location="cpu")
model = create_model()
model.load_state_dict(checkpoint['model_state_dict'])
model.eval()

# ä½¿ç”¨æ¨¡å‹è¿›è¡Œæ¨ç†
with torch.no_grad():
    outputs = model(images_t1, images_t2, captions)
    action_predictions = outputs['action_pred']
```

### 3. å¾®è°ƒè¶…å‚æ•°
æ ¹æ®ç»“æœè°ƒæ•´ `src/config.py` ä¸­çš„å‚æ•°ï¼š
- å­¦ä¹ ç‡
- æ‰¹æ¬¡å¤§å°
- LoRA é…ç½®
- è®­ç»ƒè½®æ•°

### 4. è¯„ä¼°æ¨¡å‹
åœ¨éªŒè¯é›†ä¸Šè¿è¡Œå®Œæ•´è¯„ä¼°

### 5. éƒ¨ç½²æ¨¡å‹
å°†æ¨¡å‹è½¬æ¢ä¸º ONNX æˆ– TensorRT æ ¼å¼ç”¨äºç”Ÿäº§

---

## ğŸ“š å‚è€ƒèµ„æº

### å®˜æ–¹æ–‡æ¡£
- [HuggingFace Transformers](https://huggingface.co/docs/transformers)
- [HuggingFace Datasets](https://huggingface.co/docs/datasets)
- [PyTorch æ–‡æ¡£](https://pytorch.org/docs)
- [PEFT æ–‡æ¡£](https://huggingface.co/docs/peft)

### ç›¸å…³è®ºæ–‡
- [CLIP è®ºæ–‡](https://arxiv.org/abs/2103.14030)
- [Qwen æŠ€æœ¯æŠ¥å‘Š](https://arxiv.org/abs/2309.16609)
- [LoRA è®ºæ–‡](https://arxiv.org/abs/2106.09685)

---

## ğŸ¤ æ”¯æŒ

éœ€è¦å¸®åŠ©ï¼Ÿ

1. âœ… æŸ¥çœ‹æœ¬æ–‡æ¡£çš„å¸¸è§é—®é¢˜éƒ¨åˆ†
2. âœ… é˜…è¯» [é¡¹ç›®æŒ‡å—.md](./é¡¹ç›®æŒ‡å—.md) äº†è§£æŠ€æœ¯ç»†èŠ‚
3. âœ… è¿è¡Œ `python check_setup.py` è¯Šæ–­é—®é¢˜
4. âœ… æŸ¥çœ‹æºä»£ç ä¸­çš„è¯¦ç»†æ³¨é‡Š

---

**å‡†å¤‡å¥½äº†å—? ğŸš€**

```bash
# æœ¬åœ°è®­ç»ƒ
python -m src.train

# æˆ–åœ¨ Kaggle ä¸Šéƒ¨ç½²
# æŒ‰ç…§ä¸Šè¿° Cells é€æ­¥æ‰§è¡Œ
```

ç¥ä½ è®­ç»ƒé¡ºåˆ©ï¼âœ¨

---

[è¿”å› README](./README.md) | [æŸ¥çœ‹é¡¹ç›®æŒ‡å—](./é¡¹ç›®æŒ‡å—.md)

